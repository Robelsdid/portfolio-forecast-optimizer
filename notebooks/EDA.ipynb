{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project root: c:\\Users\\aweso\\portfolio-forecast-optimizer\\portfolio-forecast-optimizer\n",
      "Src path: c:\\Users\\aweso\\portfolio-forecast-optimizer\\portfolio-forecast-optimizer\\src\n",
      "All imports successful!\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Get the absolute path to the project root\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "src_path = os.path.join(project_root, 'src')\n",
    "\n",
    "# Add to Python path\n",
    "sys.path.insert(0, project_root)\n",
    "sys.path.insert(0, src_path)\n",
    "\n",
    "print(f\"Project root: {project_root}\")\n",
    "print(f\"Src path: {src_path}\")\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "# Import classes\n",
    "from src.data.preprocess import DataPreprocessor\n",
    "from src.utils.visualization import FinancialVisualizer\n",
    "\n",
    "# Set up plotting\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "%matplotlib inline\n",
    "\n",
    "print(\"All imports successful!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data directory: c:\\Users\\aweso\\portfolio-forecast-optimizer\\portfolio-forecast-optimizer\\notebooks\\data\n",
      "Data directory exists: False\n",
      "Data directory does not exist!\n"
     ]
    }
   ],
   "source": [
    "# Check data directory contents\n",
    "import os\n",
    "\n",
    "data_dir = \"data\"\n",
    "print(f\"Data directory: {os.path.abspath(data_dir)}\")\n",
    "print(f\"Data directory exists: {os.path.exists(data_dir)}\")\n",
    "\n",
    "if os.path.exists(data_dir):\n",
    "    print(\"Contents of data directory:\")\n",
    "    for file in os.listdir(data_dir):\n",
    "        print(f\"  {file}\")\n",
    "else:\n",
    "    print(\"Data directory does not exist!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1: Data Collection\n",
      "============================================================\n",
      "PORTFOLIO FORECAST OPTIMIZER - DATA COLLECTION\n",
      "============================================================\n",
      "Output directory: c:\\Users\\aweso\\portfolio-forecast-optimizer\\portfolio-forecast-optimizer\\data\\raw\n",
      "Fetching data from 2015-07-01 to 2025-07-31\n",
      "Assets: TSLA, BND, SPY\n",
      "============================================================\n",
      "\n",
      "Fetching data for TSLA...\n",
      "Successfully fetched data for TSLA\n",
      "Data shape: (2535, 7)\n",
      "Date range: 2015-07-01 to 2025-07-30\n",
      "Data saved to c:\\Users\\aweso\\portfolio-forecast-optimizer\\portfolio-forecast-optimizer\\data\\raw\\TSLA_data.csv\n",
      "\n",
      "Basic statistics for TSLA:\n",
      "  - Total trading days: 2535\n",
      "  - Price range: $9.58 - $479.86\n",
      "  - Average volume: 114,178,885\n",
      "----------------------------------------\n",
      "\n",
      "Fetching data for BND...\n",
      "Successfully fetched data for BND\n",
      "Data shape: (2535, 8)\n",
      "Date range: 2015-07-01 to 2025-07-30\n",
      "Data saved to c:\\Users\\aweso\\portfolio-forecast-optimizer\\portfolio-forecast-optimizer\\data\\raw\\BND_data.csv\n",
      "\n",
      "Basic statistics for BND:\n",
      "  - Total trading days: 2535\n",
      "  - Price range: $60.78 - $77.32\n",
      "  - Average volume: 4,434,376\n",
      "----------------------------------------\n",
      "\n",
      "Fetching data for SPY...\n",
      "Successfully fetched data for SPY\n",
      "Data shape: (2535, 8)\n",
      "Date range: 2015-07-01 to 2025-07-30\n",
      "Data saved to c:\\Users\\aweso\\portfolio-forecast-optimizer\\portfolio-forecast-optimizer\\data\\raw\\SPY_data.csv\n",
      "\n",
      "Basic statistics for SPY:\n",
      "  - Total trading days: 2535\n",
      "  - Price range: $155.87 - $637.10\n",
      "  - Average volume: 85,035,205\n",
      "----------------------------------------\n",
      "\n",
      "Creating combined dataset...\n",
      "Combined dataset saved to c:\\Users\\aweso\\portfolio-forecast-optimizer\\portfolio-forecast-optimizer\\data\\raw\\combined_data.csv\n",
      "Combined dataset shape: (2535, 6)\n",
      "\n",
      "============================================================\n",
      "DATA COLLECTION COMPLETED\n",
      "============================================================\n",
      "\n",
      "Summary:\n",
      "  - Data saved to: c:\\Users\\aweso\\portfolio-forecast-optimizer\\portfolio-forecast-optimizer\\data\\raw\n",
      "  - Files created: 3 individual files + 1 combined file\n",
      "  - Date range: 2015-07-01 to 2025-07-31\n",
      "  - Assets: TSLA, BND, SPY\n",
      "\n",
      "Step 2: Data Preprocessing\n",
      "============================================================\n",
      "DATA PREPROCESSING\n",
      "============================================================\n",
      "\n",
      "Processing TSLA...\n",
      "Data file not found for TSLA\n",
      "\n",
      "Processing BND...\n",
      "Data file not found for BND\n",
      "\n",
      "Processing SPY...\n",
      "Data file not found for SPY\n",
      "\n",
      "============================================================\n",
      "PREPROCESSING COMPLETED\n",
      "============================================================\n",
      "\n",
      "Loaded data for 0 assets\n"
     ]
    }
   ],
   "source": [
    "# Test the complete modular workflow\n",
    "from src.data.collect_data import main as collect_data_main\n",
    "from src.data.preprocess import DataPreprocessor\n",
    "\n",
    "# Step 1: Collect data (if needed)\n",
    "print(\"Step 1: Data Collection\")\n",
    "collect_data_main()\n",
    "\n",
    "# Step 2: Process data\n",
    "print(\"\\nStep 2: Data Preprocessing\")\n",
    "preprocessor = DataPreprocessor()\n",
    "summary = preprocessor.process_all_data()\n",
    "\n",
    "# Extract processed data\n",
    "data_dict = summary['processed_data']\n",
    "stationarity_results = summary['stationarity_results']\n",
    "outlier_results = summary['outlier_results']\n",
    "\n",
    "print(f\"\\nLoaded data for {len(data_dict)} assets\")\n",
    "for ticker, data in data_dict.items():\n",
    "    print(f\"{ticker}: {data.shape[0]} data points, {data.shape[1]} features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "DATA PREPROCESSING\n",
      "============================================================\n",
      "\n",
      "Processing TSLA...\n",
      "Data file not found for TSLA\n",
      "\n",
      "Processing BND...\n",
      "Data file not found for BND\n",
      "\n",
      "Processing SPY...\n",
      "Data file not found for SPY\n",
      "\n",
      "============================================================\n",
      "PREPROCESSING COMPLETED\n",
      "============================================================\n",
      "Loaded data for 0 assets\n"
     ]
    }
   ],
   "source": [
    "# DataPreprocessor\n",
    "preprocessor = DataPreprocessor()\n",
    "summary = preprocessor.process_all_data()\n",
    "\n",
    "# Extract processed data\n",
    "data_dict = summary['processed_data']\n",
    "stationarity_results = summary['stationarity_results']\n",
    "outlier_results = summary['outlier_results']\n",
    "\n",
    "print(f\"Loaded data for {len(data_dict)} assets\")\n",
    "for ticker, data in data_dict.items():\n",
    "    print(f\"{ticker}: {data.shape[0]} data points, {data.shape[1]} features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create interactive price comparison\n",
    "fig = go.Figure()\n",
    "\n",
    "colors = ['#1f77b4', '#ff7f0e', '#2ca02c']\n",
    "for i, (ticker, data) in enumerate(data_dict.items()):\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=data.index, \n",
    "        y=data['Close'],\n",
    "        name=ticker,\n",
    "        line=dict(color=colors[i])\n",
    "    ))\n",
    "\n",
    "fig.update_layout(\n",
    "    title='Interactive Price Comparison',\n",
    "    xaxis_title='Date',\n",
    "    yaxis_title='Price ($)',\n",
    "    hovermode='x unified'\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate and display returns statistics\n",
    "returns_stats = {}\n",
    "\n",
    "for ticker, data in data_dict.items():\n",
    "    return_col = f'{ticker}_Daily_Return'\n",
    "    if return_col in data.columns:\n",
    "        returns = data[return_col].dropna()\n",
    "        returns_stats[ticker] = {\n",
    "            'Mean': returns.mean(),\n",
    "            'Std': returns.std(),\n",
    "            'Min': returns.min(),\n",
    "            'Max': returns.max(),\n",
    "            'Skewness': returns.skew(),\n",
    "            'Kurtosis': returns.kurtosis()\n",
    "        }\n",
    "\n",
    "returns_df = pd.DataFrame(returns_stats).T\n",
    "returns_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interactive volatility comparison\n",
    "fig = make_subplots(rows=3, cols=1, subplot_titles=[f'{ticker} Volatility' for ticker in data_dict.keys()])\n",
    "\n",
    "for i, (ticker, data) in enumerate(data_dict.items(), 1):\n",
    "    vol_col = f'{ticker}_Volatility_20d'\n",
    "    if vol_col in data.columns:\n",
    "        fig.add_trace(\n",
    "            go.Scatter(x=data.index, y=data[vol_col], name=f'{ticker} 20d Vol'),\n",
    "            row=i, col=1\n",
    "        )\n",
    "\n",
    "fig.update_layout(height=900, title_text=\"Rolling Volatility Comparison\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create returns correlation matrix\n",
    "returns_data = {}\n",
    "for ticker, data in data_dict.items():\n",
    "    return_col = f'{ticker}_Daily_Return'\n",
    "    if return_col in data.columns:\n",
    "        returns_data[ticker] = data[return_col]\n",
    "\n",
    "returns_df = pd.DataFrame(returns_data).dropna()\n",
    "corr_matrix = returns_df.corr()\n",
    "\n",
    "# Interactive correlation heatmap\n",
    "fig = px.imshow(\n",
    "    corr_matrix,\n",
    "    text_auto=True,\n",
    "    aspect=\"auto\",\n",
    "    title=\"Correlation Matrix of Daily Returns\"\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate comprehensive risk metrics\n",
    "risk_metrics = {}\n",
    "\n",
    "for ticker, data in data_dict.items():\n",
    "    return_col = f'{ticker}_Daily_Return'\n",
    "    if return_col in data.columns:\n",
    "        returns = data[return_col].dropna()\n",
    "        \n",
    "        # Annualized metrics\n",
    "        annual_return = returns.mean() * 252\n",
    "        annual_vol = returns.std() * np.sqrt(252)\n",
    "        sharpe_ratio = annual_return / annual_vol if annual_vol > 0 else 0\n",
    "        \n",
    "        # Drawdown\n",
    "        cumulative_returns = (1 + returns).cumprod()\n",
    "        running_max = cumulative_returns.expanding().max()\n",
    "        drawdown = (cumulative_returns - running_max) / running_max\n",
    "        max_drawdown = drawdown.min()\n",
    "        \n",
    "        # VaR and CVaR\n",
    "        var_95 = returns.quantile(0.05)\n",
    "        cvar_95 = returns[returns <= var_95].mean()\n",
    "        \n",
    "        risk_metrics[ticker] = {\n",
    "            'Annual Return': annual_return,\n",
    "            'Annual Volatility': annual_vol,\n",
    "            'Sharpe Ratio': sharpe_ratio,\n",
    "            'Max Drawdown': max_drawdown,\n",
    "            'VaR (95%)': var_95,\n",
    "            'CVaR (95%)': cvar_95\n",
    "        }\n",
    "\n",
    "risk_df = pd.DataFrame(risk_metrics).T\n",
    "risk_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display stationarity test results\n",
    "if stationarity_results:\n",
    "    stationarity_df = pd.DataFrame(stationarity_results)\n",
    "    stationarity_df[['ticker', 'adf_statistic', 'p_value', 'is_stationary']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display outlier analysis results\n",
    "if outlier_results:\n",
    "    outlier_df = pd.DataFrame(outlier_results)\n",
    "    outlier_df[['ticker', 'outlier_count', 'outlier_percentage', 'method']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Volume analysis\n",
    "fig = make_subplots(rows=3, cols=1, subplot_titles=[f'{ticker} Volume' for ticker in data_dict.keys()])\n",
    "\n",
    "for i, (ticker, data) in enumerate(data_dict.items(), 1):\n",
    "    fig.add_trace(\n",
    "        go.Scatter(x=data.index, y=data['Volume'], name=f'{ticker} Volume'),\n",
    "        row=i, col=1\n",
    "    )\n",
    "\n",
    "fig.update_layout(height=900, title_text=\"Trading Volume Comparison\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cumulative returns comparison\n",
    "fig = go.Figure()\n",
    "\n",
    "for ticker, data in data_dict.items():\n",
    "    return_col = f'{ticker}_Daily_Return'\n",
    "    if return_col in data.columns:\n",
    "        cumulative_returns = (1 + data[return_col]).cumprod()\n",
    "        fig.add_trace(go.Scatter(\n",
    "            x=data.index,\n",
    "            y=cumulative_returns,\n",
    "            name=f'{ticker} Cumulative Returns',\n",
    "            line=dict(width=2)\n",
    "        ))\n",
    "\n",
    "fig.update_layout(\n",
    "    title='Cumulative Returns Comparison',\n",
    "    xaxis_title='Date',\n",
    "    yaxis_title='Cumulative Returns',\n",
    "    hovermode='x unified'\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Risk-return scatter plot\n",
    "risk_return_data = []\n",
    "\n",
    "for ticker, data in data_dict.items():\n",
    "    return_col = f'{ticker}_Daily_Return'\n",
    "    if return_col in data.columns:\n",
    "        returns = data[return_col].dropna()\n",
    "        annual_return = returns.mean() * 252\n",
    "        annual_vol = returns.std() * np.sqrt(252)\n",
    "        risk_return_data.append([annual_vol, annual_return, ticker])\n",
    "\n",
    "if risk_return_data:\n",
    "    risk_return_df = pd.DataFrame(risk_return_data, columns=['Risk', 'Return', 'Ticker'])\n",
    "    \n",
    "    fig = px.scatter(\n",
    "        risk_return_df, \n",
    "        x='Risk', \n",
    "        y='Return', \n",
    "        text='Ticker',\n",
    "        title='Risk-Return Profile'\n",
    "    )\n",
    "    fig.update_traces(textposition=\"top center\")\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comprehensive summary table\n",
    "summary_stats = {}\n",
    "\n",
    "for ticker, data in data_dict.items():\n",
    "    return_col = f'{ticker}_Daily_Return'\n",
    "    if return_col in data.columns:\n",
    "        returns = data[return_col].dropna()\n",
    "        \n",
    "        summary_stats[ticker] = {\n",
    "            'Data Points': len(data),\n",
    "            'Date Range': f\"{data.index[0].date()} to {data.index[-1].date()}\",\n",
    "            'Mean Daily Return': f\"{returns.mean():.6f}\",\n",
    "            'Std Daily Return': f\"{returns.std():.6f}\",\n",
    "            'Annualized Return': f\"{returns.mean() * 252:.4f}\",\n",
    "            'Annualized Volatility': f\"{returns.std() * np.sqrt(252):.4f}\",\n",
    "            'Sharpe Ratio': f\"{(returns.mean() * 252) / (returns.std() * np.sqrt(252)):.4f}\",\n",
    "            'Min Return': f\"{returns.min():.6f}\",\n",
    "            'Max Return': f\"{returns.max():.6f}\",\n",
    "            'Skewness': f\"{returns.skew():.4f}\",\n",
    "            'Kurtosis': f\"{returns.kurtosis():.4f}\"\n",
    "        }\n",
    "\n",
    "summary_df = pd.DataFrame(summary_stats).T\n",
    "summary_df"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
